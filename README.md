# Fine-Tuning LLM using LoRA (PEFT)

This project demonstrates how to fine-tune a Large Language Model (TinyLlama)
using LoRA on limited compute (Google Colab).

## Features
- Parameter-Efficient Fine-Tuning (LoRA)
- No GPU required
- Gradio-based Q&A interface
- Cybersecurity domain examples

## Tech Stack
- Python
- HuggingFace Transformers
- PEFT (LoRA)
- Gradio

## How to Run
```bash
pip install -r requirements.txt
python inference/app.py
